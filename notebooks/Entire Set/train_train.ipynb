{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RVntMuAGuM4"
      },
      "source": [
        "This notebook trains and tests the Sattelite Image with help of 5 Deep Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3u5Faf_YY7S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.plot import reshape_as_image\n",
        "from sklearn.cluster import KMeans\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbuiAh4VHgfQ"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wS9Stu4GYbb6"
      },
      "outputs": [],
      "source": [
        "import os, numpy as np, tensorflow as tf, rasterio\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from rasterio.windows import Window\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "RAW_IMAGE = \"../data//raw/20241110_053942_45_24f7_3B_AnalyticMS_SR_8b_clip.tif\"\n",
        "RAW_MASK  = \"../data/raw/20241110_053942_45_24f7_3B_AnalyticMS_SR_8b_clip_Hybrid_mask.tif\"\n",
        "OUT_DIR   = \"../experiments_all\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 150\n",
        "LR = 5e-4\n",
        "def tile_raster_pair(image_path, mask_path, tile_size=IMG_SIZE, stride=None):\n",
        "    if stride is None:\n",
        "        stride = tile_size[0]\n",
        "    imgs, msks = [], []\n",
        "    with rasterio.open(image_path) as img_src, rasterio.open(mask_path) as mask_src:\n",
        "        for top in range(0, img_src.height - tile_size[0] + 1, stride):\n",
        "            for left in range(0, img_src.width - tile_size[1] + 1, stride):\n",
        "                window = Window(left, top, tile_size[1], tile_size[0])\n",
        "                img = np.moveaxis(img_src.read(window=window), 0, 2).astype(np.float32)\n",
        "                mask = mask_src.read(1, window=window).astype(np.uint8)\n",
        "                img = img / (np.max(img) + 1e-8)\n",
        "                imgs.append(img)\n",
        "                msks.append(np.expand_dims(mask, -1))\n",
        "    return np.array(imgs), np.array(msks)\n",
        "\n",
        "X, Y = tile_raster_pair(RAW_IMAGE, RAW_MASK)\n",
        "print(f\" Tiled: {len(X)} tiles â€” shape {X.shape}\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "def conv_block(x, filters):\n",
        "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return x\n",
        "def encoder_block(x, filters):\n",
        "    c = conv_block(x, filters)\n",
        "    p = layers.MaxPooling2D((2, 2))(c)\n",
        "    return c, p\n",
        "def decoder_block(x, skip, filters):\n",
        "    x = layers.Conv2DTranspose(filters, (2, 2), strides=2, padding='same')(x)\n",
        "    x = layers.concatenate([x, skip])\n",
        "    x = conv_block(x, filters)\n",
        "    return X\n",
        "def build_unet(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    c1, p1 = encoder_block(inputs, 64)\n",
        "    c2, p2 = encoder_block(p1, 128)\n",
        "    c3, p3 = encoder_block(p2, 256)\n",
        "    c4, p4 = encoder_block(p3, 512)\n",
        "    b = conv_block(p4, 1024)\n",
        "    d1 = decoder_block(b, c4, 512)\n",
        "    d2 = decoder_block(d1, c3, 256)\n",
        "    d3 = decoder_block(d2, c2, 128)\n",
        "    d4 = decoder_block(d3, c1, 64)\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(d4)\n",
        "    return models.Model(inputs, outputs, name='U-Net')\n",
        "def residual_block(x, filters):\n",
        "    shortcut = layers.Conv2D(filters, (1, 1), padding=\"same\")(x)\n",
        "    x = layers.Conv2D(filters, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(filters, (3, 3), padding=\"same\")(x)\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    return layers.Activation(\"relu\")(x)\n",
        "\n",
        "def build_resunet(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    c1 = residual_block(inputs, 64); p1 = layers.MaxPooling2D(2)(c1)\n",
        "    c2 = residual_block(p1, 128); p2 = layers.MaxPooling2D(2)(c2)\n",
        "    c3 = residual_block(p2, 256); p3 = layers.MaxPooling2D(2)(c3)\n",
        "    c4 = residual_block(p3, 512); p4 = layers.MaxPooling2D(2)(c4)\n",
        "    b = residual_block(p4, 1024)\n",
        "    u1 = layers.Conv2DTranspose(512, 2, strides=2, padding=\"same\")(b)\n",
        "    u1 = layers.Concatenate()([u1, c4]); d1 = residual_block(u1, 512)\n",
        "    u2 = layers.Conv2DTranspose(256, 2, strides=2, padding=\"same\")(d1)\n",
        "    u2 = layers.Concatenate()([u2, c3]); d2 = residual_block(u2, 256)\n",
        "    u3 = layers.Conv2DTranspose(128, 2, strides=2, padding=\"same\")(d2)\n",
        "    u3 = layers.Concatenate()([u3, c2]); d3 = residual_block(u3, 128)\n",
        "    u4 = layers.Conv2DTranspose(64, 2, strides=2, padding=\"same\")(d3)\n",
        "    u4 = layers.Concatenate()([u4, c1]); d4 = residual_block(u4, 64)\n",
        "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(d4)\n",
        "    return models.Model(inputs, outputs, name=\"ResU-Net\")\n",
        "def attention_gate(x, g, inter_channels):\n",
        "    theta_x = layers.Conv2D(inter_channels, 2, strides=2, padding=\"same\")(x)\n",
        "    phi_g = layers.Conv2D(inter_channels, 1, padding=\"same\")(g)\n",
        "    add = layers.Add()([theta_x, phi_g])\n",
        "    act = layers.Activation(\"relu\")(add)\n",
        "    psi = layers.Conv2D(1, 1, activation=\"sigmoid\")(act)\n",
        "    psi_up = layers.UpSampling2D(size=(2,2), interpolation=\"bilinear\")(psi)\n",
        "    return layers.Multiply()([x, psi_up])\n",
        "def build_attnunet(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    c1, p1 = encoder_block(inputs, 64)\n",
        "    c2, p2 = encoder_block(p1, 128)\n",
        "    c3, p3 = encoder_block(p2, 256)\n",
        "    c4, p4 = encoder_block(p3, 512)\n",
        "    b = conv_block(p4, 1024)\n",
        "    g1 = layers.Conv2D(512, 1, padding=\"same\")(b)\n",
        "    att1 = attention_gate(c4, g1, 256)\n",
        "    u1 = decoder_block(b, att1, 512)\n",
        "    g2 = layers.Conv2D(256, 1, padding=\"same\")(u1)\n",
        "    att2 = attention_gate(c3, g2, 128)\n",
        "    u2 = decoder_block(u1, att2, 256)\n",
        "    g3 = layers.Conv2D(128, 1, padding=\"same\")(u2)\n",
        "    att3 = attention_gate(c2, g3, 64)\n",
        "    u3 = decoder_block(u2, att3, 128)\n",
        "    u4 = decoder_block(u3, c1, 64)\n",
        "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(u4)\n",
        "    return models.Model(inputs, outputs, name=\"Attn-U-Net\")\n",
        "def build_attnresunet(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    c1 = residual_block(inputs, 64); p1 = layers.MaxPooling2D(2)(c1)\n",
        "    c2 = residual_block(p1, 128); p2 = layers.MaxPooling2D(2)(c2)\n",
        "    c3 = residual_block(p2, 256); p3 = layers.MaxPooling2D(2)(c3)\n",
        "    c4 = residual_block(p3, 512); p4 = layers.MaxPooling2D(2)(c4)\n",
        "    b = residual_block(p4, 1024)\n",
        "    g1 = layers.Conv2D(512, 1, padding=\"same\")(b)\n",
        "    att1 = attention_gate(c4, g1, 256)\n",
        "    u1 = layers.Conv2DTranspose(512, 2, strides=2, padding=\"same\")(b)\n",
        "    u1 = layers.Concatenate()([u1, att1]); d1 = residual_block(u1, 512)\n",
        "    g2 = layers.Conv2D(256, 1, padding=\"same\")(d1)\n",
        "    att2 = attention_gate(c3, g2, 128)\n",
        "    u2 = layers.Conv2DTranspose(256, 2, strides=2, padding=\"same\")(d1)\n",
        "    u2 = layers.Concatenate()([u2, att2]); d2 = residual_block(u2, 256)\n",
        "    u3 = layers.Conv2DTranspose(128, 2, strides=2, padding=\"same\")(d2)\n",
        "    u3 = layers.Concatenate()([u3, c2]); d3 = residual_block(u3, 128)\n",
        "    u4 = layers.Conv2DTranspose(64, 2, strides=2, padding=\"same\")(d3)\n",
        "    u4 = layers.Concatenate()([u4, c1]); d4 = residual_block(u4, 64)\n",
        "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(d4)\n",
        "    return models.Model(inputs, outputs, name=\"Attn-ResU-Net\")\n",
        "def dense_block(x, filters):\n",
        "    x1 = layers.Conv2D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x2 = layers.Conv2D(filters, 3, padding=\"same\", activation=\"relu\")(layers.Concatenate()([x, x1]))\n",
        "    x3 = layers.Conv2D(filters, 3, padding=\"same\", activation=\"relu\")(layers.Concatenate()([x, x1, x2]))\n",
        "    return layers.Concatenate()([x, x1, x2, x3])\n",
        "def multi_scale_conv(x, filters):\n",
        "    conv3 = layers.Conv2D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    conv5 = layers.Conv2D(filters, 5, padding=\"same\", activation=\"relu\")(x)\n",
        "    return layers.Concatenate()([conv3, conv5])\n",
        "def build_asdms(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    e1 = dense_block(inputs, 32); p1 = layers.MaxPooling2D(2)(e1)\n",
        "    e2 = dense_block(p1, 64); p2 = layers.MaxPooling2D(2)(e2)\n",
        "    e3 = dense_block(p2, 128); p3 = layers.MaxPooling2D(2)(e3)\n",
        "    e4 = dense_block(p3, 256); p4 = layers.MaxPooling2D(2)(e4)\n",
        "    b = multi_scale_conv(p4, 512)\n",
        "    g1 = layers.Conv2D(256, 1, padding=\"same\")(b)\n",
        "    att1 = attention_gate(e4, g1, 128)\n",
        "    u1 = layers.Conv2DTranspose(256, 2, strides=2, padding=\"same\")(b)\n",
        "    u1 = layers.Concatenate()([u1, att1]); d1 = dense_block(u1, 256)\n",
        "    u2 = layers.Conv2DTranspose(128, 2, strides=2, padding=\"same\")(d1)\n",
        "    u2 = layers.Concatenate()([u2, e3]); d2 = dense_block(u2, 128)\n",
        "    u3 = layers.Conv2DTranspose(64, 2, strides=2, padding=\"same\")(d2)\n",
        "    u3 = layers.Concatenate()([u3, e2]); d3 = dense_block(u3, 64)\n",
        "    u4 = layers.Conv2DTranspose(32, 2, strides=2, padding=\"same\")(d3)\n",
        "    u4 = layers.Concatenate()([u4, e1]); d4 = dense_block(u4, 32)\n",
        "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(d4)\n",
        "    return models.Model(inputs, outputs, name=\"ASDMS-Attn-U-Net\")\n",
        "model_builders = [\n",
        "    build_unet,\n",
        "    build_resunet,\n",
        "    build_attnunet,\n",
        "    build_attnresunet,\n",
        "    build_asdms\n",
        "]\n",
        "results = {}\n",
        "for builder in model_builders:\n",
        "    name = builder.__name__.replace(\"build_\", \"\")\n",
        "    print(f\"\\n Training {name} ...\")\n",
        "    model = builder(input_shape=X_train.shape[1:])\n",
        "    model.compile(optimizer=optimizers.Adam(LR),\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.MeanIoU(num_classes=2)])\n",
        "    hist = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_split=0.2,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        verbose=1\n",
        "    )\n",
        "    test_metrics = model.evaluate(X_test, y_test, verbose=0)\n",
        "    results[name] = {\n",
        "        \"loss\": test_metrics[0],\n",
        "        \"accuracy\": test_metrics[1],\n",
        "        \"iou\": test_metrics[2]\n",
        "    }\n",
        "    model.save(os.path.join(OUT_DIR, f\"{name}.keras\"))\n",
        "print(\"\\nðŸ“Š Final IoU Comparison on Test Set:\")\n",
        "for name, res in results.items():\n",
        "    print(f\"{name:<20}  IoU={res['iou']:.4f}  Acc={res['accuracy']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8IZ3oMOHo1t"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGQZVKtTT5Lv"
      },
      "outputs": [],
      "source": [
        "import os, numpy as np, matplotlib.pyplot as plt, rasterio\n",
        "from tensorflow.keras.models import load_model\n",
        "from rasterio.windows import Window\n",
        "RAW_IMAGE = \"/content/drive/MyDrive/Villangad_2020/data/raw/20241110_053942_45_24f7_3B_AnalyticMS_SR_8b_clip.tif\"\n",
        "RAW_MASK  = \"/content/drive/MyDrive/Villangad_2020/data/raw/20241110_053942_45_24f7_3B_AnalyticMS_SR_8b_clip_Hybrid_mask.tif\"\n",
        "MODEL_DIR = \"/content/drive/MyDrive/Villangad_2020/experiments_all\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/Villangad_2020/experiments_all/full_comparison_scene.png\"\n",
        "with rasterio.open(RAW_IMAGE) as src:\n",
        "    img = np.moveaxis(src.read(), 0, 2).astype(np.float32)\n",
        "    img = img / (np.max(img) + 1e-8)\n",
        "with rasterio.open(RAW_MASK) as msk_src:\n",
        "    mask = msk_src.read(1).astype(np.uint8)\n",
        "print(f\"Image shape: {img.shape}, Mask shape: {mask.shape}\")\n",
        "def tile_image(img, tile_size=(256, 256)):\n",
        "    tiles, coords = [], []\n",
        "    h, w, _ = img.shape\n",
        "    for top in range(0, h, tile_size[0]):\n",
        "        for left in range(0, w, tile_size[1]):\n",
        "            bottom = min(top + tile_size[0], h)\n",
        "            right  = min(left + tile_size[1], w)\n",
        "            tile = img[top:bottom, left:right]\n",
        "            if tile.shape[0] < tile_size[0] or tile.shape[1] < tile_size[1]:\n",
        "                pad_h = tile_size[0] - tile.shape[0]\n",
        "                pad_w = tile_size[1] - tile.shape[1]\n",
        "                tile = np.pad(tile, ((0, pad_h), (0, pad_w), (0,0)), mode='reflect')\n",
        "            tiles.append(tile)\n",
        "            coords.append((top, left, bottom, right))\n",
        "    return np.array(tiles), coords\n",
        "def merge_tiles(preds, coords, shape, tile_size=(256,256)):\n",
        "    \"\"\"Merge predicted tiles (with channel dim) back into full image.\"\"\"\n",
        "    full_pred = np.zeros((shape[0], shape[1], 1), dtype=np.float32)\n",
        "    for pred, (top, left, bottom, right) in zip(preds, coords):\n",
        "        pred = np.squeeze(pred)  # remove channel dim\n",
        "        h, w = bottom - top, right - left\n",
        "        full_pred[top:top+h, left:left+w, 0] = pred[:h, :w]\n",
        "    return np.squeeze(full_pred)\n",
        "model_names = [\n",
        "    \"unet\",\n",
        "    \"resunet\",\n",
        "    \"attnunet\",\n",
        "    \"attnresunet\",\n",
        "    \"asdms\"\n",
        "]\n",
        "models_dict = {}\n",
        "for name in model_names:\n",
        "    path = os.path.join(MODEL_DIR, f\"{name}.keras\")\n",
        "    models_dict[name] = load_model(path, compile=False)\n",
        "    print(f\" Loaded: {name}\")\n",
        "print(\"ðŸ”® Predicting full scene for all models...\")\n",
        "tiles, coords = tile_image(img)\n",
        "print(f\"Total tiles: {len(tiles)}\")\n",
        "pred_maps = {}\n",
        "for name, model in models_dict.items():\n",
        "    preds = model.predict(tiles, verbose=0)\n",
        "    preds_bin = (preds > 0.5).astype(np.uint8)\n",
        "    merged = merge_tiles(preds_bin, coords, img.shape)\n",
        "    pred_maps[name] = merged\n",
        "    print(f\" {name} prediction complete\")\n",
        "rgb = img[..., [3, 2, 1]]\n",
        "rgb = (rgb - np.min(rgb)) / (np.max(rgb) - np.min(rgb) + 1e-8)\n",
        "plt.figure(figsize=(25, 6))\n",
        "titles = [\"Satellite RGB\", \"Ground Truth\"] + [name.replace(\"_\", \" \").upper() for name in model_names]\n",
        "images = [rgb, mask] + [pred_maps[n] for n in model_names]\n",
        "for i, (title, im) in enumerate(zip(titles, images), 1):\n",
        "    plt.subplot(1, len(images), i)\n",
        "    if i == 1:\n",
        "        plt.imshow(im)\n",
        "    else:\n",
        "        plt.imshow(im, cmap=\"gray\")\n",
        "    plt.title(title, fontsize=10)\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(SAVE_PATH, dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(f\" Saved single composite comparison image at:\\n{SAVE_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
