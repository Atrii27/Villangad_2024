{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RVntMuAGuM4"
      },
      "source": [
        "This notebook trains and tests the Sattelite Image with help of 5 Deep Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, random, numpy as np, matplotlib.pyplot as plt, tensorflow as tf\n",
        "import rasterio, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, jaccard_score, accuracy_score\n",
        "from tensorflow.keras import layers, Model\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "RAW_IMAGE = \"../data/raw/20241110_053942_45_24f7_3B_AnalyticMS_SR_8b_clip.tif\"\n",
        "RAW_MASK  = \"../data/raw/20241110_053942_45_24f7_3B_AnalyticMS_SR_8b_clip_Hybrid_mask.tif\"\n",
        "OUT_DIR   = \"../experiments_final\"\n",
        "PRED_DIR  = os.path.join(OUT_DIR, \"test_predictions\")\n",
        "os.makedirs(PRED_DIR, exist_ok=True)\n",
        "def load_tif_image(path):\n",
        "    with rasterio.open(path) as src:\n",
        "        img = np.moveaxis(src.read(), 0, 2).astype(np.float32)\n",
        "        img = img / (np.max(img) + 1e-8)\n",
        "    return img\n",
        "def load_mask(path):\n",
        "    with rasterio.open(path) as src:\n",
        "        mask = src.read(1).astype(np.uint8)\n",
        "    return mask\n",
        "img = load_tif_image(RAW_IMAGE)\n",
        "mask = load_mask(RAW_MASK)\n",
        "print(\" Loaded:\", img.shape, mask.shape)\n",
        "def create_tiles(image, mask, tile_size=256):\n",
        "    tiles_img, tiles_mask = [], []\n",
        "    H, W, _ = image.shape\n",
        "    for i in range(0, H, tile_size):\n",
        "        for j in range(0, W, tile_size):\n",
        "            sub_img = image[i:i+tile_size, j:j+tile_size]\n",
        "            sub_mask = mask[i:i+tile_size, j:j+tile_size]\n",
        "            if sub_img.shape[0] == tile_size and sub_img.shape[1] == tile_size:\n",
        "                tiles_img.append(sub_img)\n",
        "                tiles_mask.append(sub_mask[..., np.newaxis])\n",
        "    return np.array(tiles_img), np.array(tiles_mask)\n",
        "tiles_img, tiles_mask = create_tiles(img, mask)\n",
        "print(\" Total Tiles:\", tiles_img.shape, tiles_mask.shape)\n",
        "non_empty = np.sum(tiles_mask, axis=(1,2,3)) > 0\n",
        "tiles_img, tiles_mask = tiles_img[non_empty], tiles_mask[non_empty]\n",
        "print(\" Non-empty Tiles:\", tiles_img.shape)\n",
        "trainX, tempX, trainY, tempY = train_test_split(tiles_img, tiles_mask, test_size=0.75, random_state=SEED)\n",
        "valX, testX, valY, testY = train_test_split(tempX, tempY, test_size=2/3, random_state=SEED)\n",
        "print(f\" Split â€” Train: {len(trainX)}, Val: {len(valX)}, Test: {len(testX)}\")\n",
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        return tf.reduce_mean(alpha * (1 - p_t)**gamma * bce)\n",
        "    return loss\n",
        "def conv_block(x, filters):\n",
        "    x = layers.Conv2D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return x\n",
        "def residual_block(x, filters):\n",
        "    skip = layers.Conv2D(filters, 1, padding=\"same\")(x)\n",
        "    x = layers.Conv2D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Add()([x, skip])\n",
        "    return layers.Activation(\"relu\")(x)\n",
        "def attention_gate(x, g, filters):\n",
        "    g1 = layers.Conv2D(filters, 1, padding=\"same\")(g)\n",
        "    x1 = layers.Conv2D(filters, 1, padding=\"same\")(x)\n",
        "    psi = layers.Activation(\"relu\")(layers.Add()([g1, x1]))\n",
        "    psi = layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(psi)\n",
        "    return layers.Multiply()([x, psi])\n",
        "def build_unet(shape):\n",
        "    inputs = layers.Input(shape)\n",
        "    s1 = conv_block(inputs, 64); p1 = layers.MaxPooling2D()(s1)\n",
        "    s2 = conv_block(p1, 128); p2 = layers.MaxPooling2D()(s2)\n",
        "    s3 = conv_block(p2, 256); p3 = layers.MaxPooling2D()(s3)\n",
        "    s4 = conv_block(p3, 512); p4 = layers.MaxPooling2D()(s4)\n",
        "    b = conv_block(p4, 1024)\n",
        "    d1 = layers.Conv2DTranspose(512, 2, strides=2, padding=\"same\")(b)\n",
        "    d1 = layers.concatenate([d1, s4]); d1 = conv_block(d1, 512)\n",
        "    d2 = layers.Conv2DTranspose(256, 2, strides=2, padding=\"same\")(d1)\n",
        "    d2 = layers.concatenate([d2, s3]); d2 = conv_block(d2, 256)\n",
        "    d3 = layers.Conv2DTranspose(128, 2, strides=2, padding=\"same\")(d2)\n",
        "    d3 = layers.concatenate([d3, s2]); d3 = conv_block(d3, 128)\n",
        "    d4 = layers.Conv2DTranspose(64, 2, strides=2, padding=\"same\")(d3)\n",
        "    d4 = layers.concatenate([d4, s1]); d4 = conv_block(d4, 64)\n",
        "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(d4)\n",
        "    return Model(inputs, outputs, name=\"UNet\")\n",
        "def build_resunet(shape):\n",
        "    inputs = layers.Input(shape)\n",
        "    s1 = residual_block(inputs, 64); p1 = layers.MaxPooling2D()(s1)\n",
        "    s2 = residual_block(p1, 128); p2 = layers.MaxPooling2D()(s2)\n",
        "    s3 = residual_block(p2, 256); p3 = layers.MaxPooling2D()(s3)\n",
        "    s4 = residual_block(p3, 512); p4 = layers.MaxPooling2D()(s4)\n",
        "    b = residual_block(p4, 1024)\n",
        "    d1 = layers.Conv2DTranspose(512, 2, strides=2, padding=\"same\")(b)\n",
        "    d1 = layers.concatenate([d1, s4]); d1 = residual_block(d1, 512)\n",
        "    d2 = layers.Conv2DTranspose(256, 2, strides=2, padding=\"same\")(d1)\n",
        "    d2 = layers.concatenate([d2, s3]); d2 = residual_block(d2, 256)\n",
        "    d3 = layers.Conv2DTranspose(128, 2, strides=2, padding=\"same\")(d2)\n",
        "    d3 = layers.concatenate([d3, s2]); d3 = residual_block(d3, 128)\n",
        "    d4 = layers.Conv2DTranspose(64, 2, strides=2, padding=\"same\")(d3)\n",
        "    d4 = layers.concatenate([d4, s1]); d4 = residual_block(d4, 64)\n",
        "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(d4)\n",
        "    return Model(inputs, outputs, name=\"ResUNet\")\n",
        "def build_attnunet(shape):\n",
        "    inputs = layers.Input(shape)\n",
        "    s1 = conv_block(inputs, 64); p1 = layers.MaxPooling2D()(s1)\n",
        "    s2 = conv_block(p1, 128); p2 = layers.MaxPooling2D()(s2)\n",
        "    s3 = conv_block(p2, 256); p3 = layers.MaxPooling2D()(s3)\n",
        "    s4 = conv_block(p3, 512); p4 = layers.MaxPooling2D()(s4)\n",
        "    b = conv_block(p4, 1024)\n",
        "    g4 = layers.Conv2DTranspose(512, 2, strides=2, padding=\"same\")(b)\n",
        "    s4a = attention_gate(s4, g4, 512)\n",
        "    d1 = layers.concatenate([g4, s4a]); d1 = conv_block(d1, 512)\n",
        "    g3 = layers.Conv2DTranspose(256, 2, strides=2, padding=\"same\")(d1)\n",
        "    s3a = attention_gate(s3, g3, 256)\n",
        "    d2 = layers.concatenate([g3, s3a]); d2 = conv_block(d2, 256)\n",
        "    g2 = layers.Conv2DTranspose(128, 2, strides=2, padding=\"same\")(d2)\n",
        "    s2a = attention_gate(s2, g2, 128)\n",
        "    d3 = layers.concatenate([g2, s2a]); d3 = conv_block(d3, 128)\n",
        "    g1 = layers.Conv2DTranspose(64, 2, strides=2, padding=\"same\")(d3)\n",
        "    s1a = attention_gate(s1, g1, 64)\n",
        "    d4 = layers.concatenate([g1, s1a]); d4 = conv_block(d4, 64)\n",
        "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(d4)\n",
        "    return Model(inputs, outputs, name=\"AttnUNet\")\n",
        "def build_attnresunet(shape):\n",
        "    inputs = layers.Input(shape)\n",
        "    s1 = residual_block(inputs, 64); p1 = layers.MaxPooling2D()(s1)\n",
        "    s2 = residual_block(p1, 128); p2 = layers.MaxPooling2D()(s2)\n",
        "    s3 = residual_block(p2, 256); p3 = layers.MaxPooling2D()(s3)\n",
        "    s4 = residual_block(p3, 512); p4 = layers.MaxPooling2D()(s4)\n",
        "    b = residual_block(p4, 1024)\n",
        "    g4 = layers.Conv2DTranspose(512, 2, strides=2, padding=\"same\")(b)\n",
        "    s4a = attention_gate(s4, g4, 512)\n",
        "    d1 = layers.concatenate([g4, s4a]); d1 = residual_block(d1, 512)\n",
        "    g3 = layers.Conv2DTranspose(256, 2, strides=2, padding=\"same\")(d1)\n",
        "    s3a = attention_gate(s3, g3, 256)\n",
        "    d2 = layers.concatenate([g3, s3a]); d2 = residual_block(d2, 256)\n",
        "    g2 = layers.Conv2DTranspose(128, 2, strides=2, padding=\"same\")(d2)\n",
        "    s2a = attention_gate(s2, g2, 128)\n",
        "    d3 = layers.concatenate([g2, s2a]); d3 = residual_block(d3, 128)\n",
        "    g1 = layers.Conv2DTranspose(64, 2, strides=2, padding=\"same\")(d3)\n",
        "    s1a = attention_gate(s1, g1, 64)\n",
        "    d4 = layers.concatenate([g1, s1a]); d4 = residual_block(d4, 64)\n",
        "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(d4)\n",
        "    return Model(inputs, outputs, name=\"AttnResUNet\")\n",
        "def build_asdms(shape):\n",
        "    inputs = layers.Input(shape)\n",
        "    s1 = conv_block(inputs, 64); p1 = layers.MaxPooling2D()(s1)\n",
        "    s2 = conv_block(p1, 128); p2 = layers.MaxPooling2D()(s2)\n",
        "    s3 = conv_block(p2, 256); p3 = layers.MaxPooling2D()(s3)\n",
        "    s4 = conv_block(p3, 512); p4 = layers.MaxPooling2D()(s4)\n",
        "    b = conv_block(p4, 1024)\n",
        "    d1 = layers.Conv2DTranspose(512, 2, strides=2, padding=\"same\")(b)\n",
        "    d1 = layers.concatenate([d1, s4]); d1 = conv_block(d1, 512)\n",
        "    d2 = layers.Conv2DTranspose(256, 2, strides=2, padding=\"same\")(d1)\n",
        "    d2 = layers.concatenate([d2, s3]); d2 = conv_block(d2, 256)\n",
        "    d3 = layers.Conv2DTranspose(128, 2, strides=2, padding=\"same\")(d2)\n",
        "    d3 = layers.concatenate([d3, s2]); d3 = conv_block(d3, 128)\n",
        "    d4 = layers.Conv2DTranspose(64, 2, strides=2, padding=\"same\")(d3)\n",
        "    d4 = layers.concatenate([d4, s1]); d4 = conv_block(d4, 64)\n",
        "    out1 = layers.Conv2D(1, 1, activation=\"sigmoid\")(d1)\n",
        "    out2 = layers.Conv2D(1, 1, activation=\"sigmoid\")(d2)\n",
        "    out3 = layers.Conv2D(1, 1, activation=\"sigmoid\")(d3)\n",
        "    out4 = layers.Conv2D(1, 1, activation=\"sigmoid\")(d4)\n",
        "    outputs = layers.Average()([out1, out2, out3, out4])\n",
        "    return Model(inputs, outputs, name=\"ASDMS\")\n",
        "def train_and_predict(name, builder, X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
        "    model = builder((256,256,img.shape[-1]))\n",
        "    model.compile(optimizer='adam', loss=focal_loss(), metrics=['accuracy'])\n",
        "    print(f\" Training {name}...\")\n",
        "    model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=60, batch_size=4, verbose=1)\n",
        "    model.save(os.path.join(OUT_DIR, f\"{name}.keras\"))\n",
        "    preds = (model.predict(X_test, verbose=0) > 0.5).astype(np.uint8)\n",
        "    metrics = {\n",
        "        \"IoU\": jaccard_score(Y_test.flatten(), preds.flatten(), zero_division=0),\n",
        "        \"F1\": f1_score(Y_test.flatten(), preds.flatten(), zero_division=0),\n",
        "        \"Acc\": accuracy_score(Y_test.flatten(), preds.flatten())\n",
        "    }\n",
        "    model_dir = os.path.join(PRED_DIR, name)\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for i, (x, y, p) in enumerate(zip(X_test, Y_test, preds)):\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
        "        rgb = x[..., :3]; rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min() + 1e-8)\n",
        "        axs[0].imshow(rgb); axs[0].set_title(\"Satellite\"); axs[0].axis(\"off\")\n",
        "        axs[1].imshow(y.squeeze(), cmap=\"gray\"); axs[1].set_title(\"Ground Truth\"); axs[1].axis(\"off\")\n",
        "        axs[2].imshow(p.squeeze(), cmap=\"gray\"); axs[2].set_title(f\"{name} Prediction\"); axs[2].axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(model_dir, f\"tile_{i:04d}.png\"), dpi=150)\n",
        "        plt.close()\n",
        "    return metrics\n",
        "builders = {\n",
        "    \"unet\": build_unet,\n",
        "    \"resunet\": build_resunet,\n",
        "    \"attnunet\": build_attnunet,\n",
        "    \"attnresunet\": build_attnresunet,\n",
        "    \"asdms\": build_asdms\n",
        "}\n",
        "results = {}\n",
        "for name, builder in builders.items():\n",
        "    metrics = train_and_predict(name, builder, trainX, trainY, valX, valY, testX, testY)\n",
        "    results[name] = metrics\n",
        "    print(f\" {name}: IoU={metrics['IoU']:.4f}, F1={metrics['F1']:.4f}, Acc={metrics['Acc']:.4f}\")\n",
        "df = pd.DataFrame(results).T\n",
        "csv_path = os.path.join(OUT_DIR, \"results_summary.csv\")\n",
        "df.to_csv(csv_path)\n",
        "print(\"\\n Metrics saved to:\", csv_path)\n",
        "print(df)\n",
        "print(\"\\n All test predictions saved to:\", PRED_DIR)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
